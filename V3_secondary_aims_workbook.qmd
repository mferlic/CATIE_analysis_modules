---
title: "V3: Secondary Aims Analysis"
subtitle: "Using moderators and Q-learning to construct more deeply-tailored Adaptive Interventions"
author:   
  - name: Mason Ferlic
    orcid: 0000-0003-4170-2722
  - name: Jamie Yap
    orcid: 0000-0002-0899-7146
  - name: John J. Dziak
    orcid: 0000-0003-0762-5495
  - name: Daniel Almirall
    orcid: 0000-0002-9697-6600

title-block-banner: "#dafffe" 
title-block-banner-color: "#000000"
format: 
  html:
    page-layout: article
    df-print: kable
    smooth-scroll: true
    code-overflow: scroll
    code-line-numbers: true
    code-block-bg: true
    toc: true
    toc-location: left
    toc-depth: 3
    toc-title: "Outline"
    toc-expand: true
    number-sections: true
    number-depth: 2
    cap-location: top
    embed-resources: true
    css: my_style.css

editor: visual
editor_options: 
  chunk_output_type: inline
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(tidy = TRUE, fig.pos = 'H', warning = FALSE, message = FALSE, digits = 2)

options(digits = 3)

```

# Learning Goals

A typical secondary aim analysis from a SMART involves using the data to
learn a set of decision rules for a more deeply-tailored adaptive
intervention. A more deeply-tailored AI is an adaptive intervention that
includes additional tailoring variables beyond those embedded by design.
The proposed AI leads to better outcomes. In this workbook, we will
implement Q-learning to address this type of secondary aim.

Q-learning uses a subset of moderators to test the utility of candidate
tailoring variables for tailoring first and second-stage intervention
options in a 2-stage SMART. Q-learning leads to a proposal for an AI
that uses baseline and time-varying covariates to tailor treatment.

In this workbook we will:

1.  Learn how to implement Q-learning to estimate the effect of a
    more-deeply tailored AI.

    -   Fit and interpret moderated regression models
    -   Implement the R Package `qlaci`

# Setup

Load required packages

```{r}
#| results: hide
#| warning: false

# R packages for analysis
library(geepack)
library(emmeans)
library(qlaci)

# R packages for visuals/data 
library(ggplot2)
library(dplyr)
library(kableExtra)

source("./R/estimate.R")
```

# Load simulated data

This is data that was *simulated* to mimic data arising from the ADHD
SMART study (PI: William Pelham). An accompanying handout
("ADHD_SMART_handout.pdf") describes the variables in the data set.

```{r}
# Load data
dat_adhd <- read.csv("data/adhd-simulated-2023.csv")
```

![ADHD study prototypical
SMART](assets/adhd_smart_design_with_probs.png){.sidebar.toc-left
fig-align="center"}

## Examine data {.unnumbered .unlisted}

::: {.callout-tip collapse="true" appearance="simple" icon="false"}
## ADHD dataset variable descriptions

**Baseline covariates:**

-   `ID` subject identifier

-   `odd` Oppositional Defiant Disorder diagnosis, reflecting whether
    the child was (coded as 1) or was not (coded as 0) diagnosed with
    ODD before the first-stage intervention.

-   `severity` ADHD score, reflecting ADHD symptoms at the end of the
    previous school year (larger values reflect greater symptoms). Range
    0-10.

-   `priormed` medication prior to first-stage intervention, reflecting
    whether the child did (coded as 1) or did not (coded as 0) receive
    medication during the previous school year.

-   `race` white (coded 1) versus non-white (coded 0).

**Intermediate covariates:**

-   `R` response status. R = 0 if child was classified as non-responder
    to first stage intervention, R= 1 if they were classified as a
    responder.

-   `NRtime` months at which child was classified as non-responder.
    Range 2-8. Undefined for responders.

-   `adherence` adherence to the stage 1 intervention. Reflecting
    whether the child did (coded as 1) or did not (coded as 0) show high
    adherence to initial treatment.

**Treatments:**

We use effect coding (contrast coding) to denote the two levels of
treatment assignment. The primary benefit of effect coding is that we
get interpretable estimates of both the main effects and interactions.

-   `A1` stage 1 treatment assignment. Randomized with probability $0.5$
    to Medication (MED, $A_1=-1$) or Behavioral Intervention (BMOD,
    $A_1=1$).

-   `A2` stage 2 treatment assignment for non-responders. Non-responders
    we randomized with probability $0.5$ to receive Augmented (AUG,
    $A_2=-1$) or Intensified (INT, $A_2=1$) care. Undefined for
    responders.

**Outcomes**

-   `Y0` baseline school performance (higher values reflect better
    performance).

-   `Y1` mid-year school performance.

-   `Y2` end-of-year school performance (primary outcome for analysis)
:::

```{r}
#| tbl-cap: "ADHD SMART data"
#| echo: false
dat_adhd %>% kable() %>%
  kable_styling() %>%
  scroll_box(height = "400px")
```

------------------------------------------------------------------------

# Q-learning

Q-learning is an extension of moderator analysis that uses backwards
induction to learn a set of optimal decision rules for a more
deeply-tailored adaptive intervention. The proposed adaptive
intervention incorporates synergy between the first and second-stage
decision rules. Crucially, this approach bypasses the causal problems
associated with a single regression model.

Q-learning has four steps:

1.  Fit a stage 2 moderated regression model:
    $$Y_2 \sim A_2 \mid S_0, A_1, S_1$$
    a.  Obtain optimal stage 2 decision rule: $A^{opt}_2(S_0, A_1, S_1)$
2.  Predict the stage 2 outcome under the optimal decision rule:
    $\hat{Y}_{2i}(A_2^{opt})$
3.  Fit a stage 1 moderated regression model on
    $$\hat{Y}_2(A_2^{opt}) \sim A_1 \mid S_0$$
    a.  Obtain optimal stage 1 decision rule (accounting for optimal
        second stage): $A_1^{opt}(S_0)$
4.  (optional) Estimate mean outcome of optimal AI:
    $E[Y(A_1^{opt}, A_2^{opt})]$

## Step 1: second-stage tailoring

Recall that in Q-learning that we conduct the analysis backwards
starting with second-stage treatment. We would like learn whether we can
use baseline or intermediate covariates to select an optimal
second-stage tactic for **non-responders.** For example, whether
covariates such as the initial treatment $A_1$ and adherence to initial
treatment `adherence` moderate the effect of $A_2$.

> We hypothesize that for children who are non-adherent to first-stage
> treatment it will be better to AUGment ($A_2=-1$) with the alternative
> treatment as opposed to INTensifying ($A_2=1$) the current treatment.

### Regression model

We test this secondary aim by fitting a **moderated regression model**
using data from non-responders. This model examines whether binary
intermediate outcome variable `adherence` $(S_1)$ and first-stage
treatment $A_1$, moderate the effect of second-stage treatment $A_2$ on
end-of-year outcome $Y_2$, controlling for other baseline covariates
$\mathbf{X}$. The model is as follows:

$$
\begin{align*} 
E[Y \mid \mathbf{X}, A_1, S_1, R = 0, A_2] &= \beta_0 + \eta_{1:4}^T\mathbf{X}_c + \eta_5 A_{1} + \eta_6S_1 \\ 
&+ \beta_1 A_2 + 
\beta_2 A_1 A_2 + \beta_3S_1A_2 + \beta_4A_1S_1A_2
\end{align*}
$$ {#eq-mod2}

::: callout-tip
We interact $A_2$ with the uncentered variable `adherence` since we are
interested in the effect of $A_2$ at the each of the two levels:
adherent (0) and non-adherent (1).
:::

First, subset data.frame to non-responders $(R=0)$ and center baseline
covariates.

```{r}
dat_adhd_nr <- filter(dat_adhd, R == 0) # subset data.frame to non-responders

dat_adhd_nr <- dat_adhd_nr %>% mutate(across(c(odd, severity, priormed, race), ~ .x - mean(.x), .names = "{.col}_c"))

head(dat_adhd_nr) %>% kable() # view top 6 rows
```

Next, fit a moderated regression to the subset of non-responders.
Interact $A_2$ with $A_1$ and `adherence` $(S_1)$ and the interaction.

```{r}
mod_QL_A2 <- lm(Y2 ~ odd_c + severity_c + priormed_c + race_c + A1 + adherence + A2+ A1:A2 + adherence:A2 + adherence:A1:A2, 
                        data = dat_adhd_nr)

summary(mod_QL_A2)
```

::: callout-warning
Remember we are going backwards to get the effect of $A_2$ among
non-responders. This regression does not estimate the main effect of
$A_1$. We will do that later.
:::

\
The regression model from @eq-mod2 gives us the effect of $A_2$ among
non-responders. Looking at the output we find that `adherence` is a
significant moderator of stage 2 treatment, but $A_1$ is not.

### Knowledge check #1

::: callout-note
#### Questions

1.  Why do we subset to non-responders when fitting a second-stage
    moderated regression?
:::

### Marginal means of stage 2

We will use a very nice package called `emmeans` to estimate the
marginal mean of end-of-year school performance under different
treatment/covariate options. We could do this by writing custom
contrasts of the model coefficients (like in the `estimate()` func), but
`emmeans` does this for us.

::: callout-tip
Marginal means refers to estimating the expected value while holding
some covariates constant and averaging over the rest.
:::

We use the fitted moderated regression model given in @eq-mod2 to
estimate the average effect of second-stage treatment, among
non-responders, conditional on levels of `adherence` and `A1`.

```{r}
# The formula notation denotes the mean outcome under all combination of the factors A1, A2, given levels of adherence.
# We specify weights=proportional since we want to average over the observed distribution of the other baseline covariates.

em2 <- emmeans::emmeans(mod_QL_A2, ~ A2 | A1*adherence, weights = "proportional")

print(em2)
```

### Interaction plot of stage 2

We can also use the `emmeans` package to visualize the estimated mean
outcome for non-responders under each tactic.

```{r}
ep2 <- emmeans::emmip(em2,  A2 ~ adherence | A1, style = "factor") # Interaction plot for trace.factors ~ x.factors
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Prettify the plot
ep2$data %>% mutate(across(1:3, as.factor)) %>%
  ggplot(aes(xvar, yvar, color = A2, group = tvar)) +
  geom_line() +
  geom_point() +
  facet_wrap(vars(A1), labeller = "label_both") +
  scale_color_manual("A2", values = c("-1" = "darkgreen", "1" = "purple"), 
                     labels = c("-1" = "-1 AUG", "1" = "1 INT")) +
  scale_linetype_manual("A1", 
                        labels = c("-1" = "-1 MED", "1" = "1 BMOD")) +
  labs(title = "Moderator analysis of stage 2 intervention options",
       x = "Adherence to stage 1",
       y = "EOS School Performance \n (higher is better)") +
  scale_x_discrete(labels = c("Non-adherent", "Adherent")) +
  theme_classic()
```

The results from the moderated regression and the marginal means output
suggest that for those children who are non-adherent (`adherence` = 0)
it is better to Augment ($A_2 = -1$) rather than intensify. Likewise,
for those children that are adherent (`adherence` = 1) it is better to
Intensify ($A_2=1$). Notice, our optimal tactic does not depend on
first-stage treatment $A1$.

### Knowledge check #2

::: callout-note
#### Questions

1.  What is the optimal tactic for non-adhering, non-responders to $A_1$
    = BMOD(1)? To $A_1$ = MED(-1)?
:::

------------------------------------------------------------------------

## Step 2: predict optimal outcome

The optimal second-stage tactic learned from the moderated regression:

$$
A_2^{opt} = \begin{cases} 
1  \text{ INT} & \text{ if } \text{ adherence} = 1 \\
-1 \text{ AUG} & \text{ if } \text{ adherence} = 0 
\end{cases}
$$

Create new data.frame with optimal $A_2^{opt}$ for every non-responding
child

```{r}
# Assign optimal second-stage tactic using learned decision rule
dat_adhd_nr_optA2 <- dat_adhd_nr %>% 
  mutate(A2 = if_else(adherence == 1, 1, -1)) 
```

Predict outcome for non-responders under the optimal treatment
assignment:

$$
\hat{Y}_i(A^{opt}_2)
$$

```{r}
dat_adhd_nr_optA2$Y2_optA2 <- predict(mod_QL_A2, 
                                      newdata = dat_adhd_nr_optA2) # using the stage 2 moderated regression model
head(dat_adhd_nr_optA2) %>% kable()
```

## Step 3: first-stage tailoring

We would now like to use baseline information to learn an optimal
first-stage tactic *accounting for our future optimal second-stage
decision*

> We hypothesize that children already on medication (`priormed` = 1)
> will be better-off, on average, starting with MED ($A1 = -1$) instead
> of BMOD ($A1 = 1$) due to parent/child habituation with taking
> medication.

### Data.frame with adjusted outcomes

Merge predicted outcome from non-responders with the observed outcome
from responders

```{r}
# Responders get assigned their observed outcome (no stage 2 tactic)
dat_adhd_r <- dat_adhd %>% filter(R == 1) %>%
  mutate(Y2_optA2 = Y2)

# combine non-responders w/ responders
dat_adhd_optA2 <- bind_rows(dat_adhd_nr_optA2, dat_adhd_r)

# center baseline control variables across responders and non-responders
dat_adhd_optA2 <- dat_adhd_optA2 %>% mutate(across(c(odd, severity, race), ~ .x - mean(.x), .names = "{.col}_c")) 

dat_adhd_optA2 %>% kable() %>%
  kable_styling() %>%
  scroll_box(height = "300px")
```

We now have a data frame of responders and non-responders with the
estimated optimal outcome for non-responders tailored by `adherence` and
$A_1$.

### Regression model

We fit a moderated regression model for first-stage treatment using the
`dat_adhd_optA2` data frame, which accounts for the optimal future
second-stage tactic. The tailoring variable of interest is `priormed`
$(S_0)$.

$$
\begin{align*}
E[\hat{Y}(A_2^{opt}) \mid \mathbf{X}, S_0, A_1] &= \beta_0 + 
\eta_{1:3}^TX + \eta_4S_0 \\ 
&+ \beta_1A_1 + \beta_2S_0A_1
\end{align*}
$$ {#eq-Qmod1}

```{r}
# Moderator regression for first stage tailoring on priormed, controlling for optimal future tactic. We use uncentered priormed because we want to examine the interaction effect at different levels.

mod_QL_A1 <- lm(Y2_optA2 ~ odd_c + severity_c + race_c + priormed 
                + A1 + A1:priormed,
                data = dat_adhd_optA2)

summary(mod_QL_A1)
```

::: callout-warning
The standard errors (and p-values) in the step 3 regression are
potentially incorrect because they don't take into account sampling
error in estimation of $\hat{Y}(A_2^{opt})$. Luckily, we provide
software (see `qlaci`) to do proper inference!
:::

We use `emmeans` package to estimate the expected end-of-year school
performance for an adaptive intervention that offers BMOD(1) or MED(-1)
at first-stage for levels of `priormed`, adjusting for the fact we are
optimally tailoring second-stage treatment for non-responders by
`adherence`.

```{r}
qem1 <- emmeans::emmeans(mod_QL_A1, ~ A1 | priormed, 
                         weights = "proportional")

print(qem1, infer = FALSE)
```

### Interaction plot of optimal tactic

```{r}
# Interaction plot of A1 with priormed
qep1 <- emmeans::emmip(mod_QL_A1, A1 ~ priormed, style = "factor", 
                       weights = "proportional")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Prettify plot  
qep1$data %>% mutate(across(1:2, as.factor)) %>%
  ggplot(aes(xvar, yvar, color = A1, group = tvar)) +
  geom_line(linewidth = 1) +
  geom_point() +
  scale_color_manual("A1", values = c("-1" = "red", "1" = "blue"), 
                     labels = c("-1" = "-1 MED", "1" = "1 BMOD")) +
  theme_classic() +
  labs(title = "Moderator of stage 1 controlling for optimal stage 2",
       x = "Medication use in Prior year",
       y = "EOS School Performance \n (higher is better)") +
  scale_x_discrete(labels = c("No prior med", "Prior med")) +
  scale_y_continuous(n.breaks = 8)
```

## Step 4: Estimated outcome under the more deeply-tailored AI

The results of Q-learning generated a proposal for a more
deeply-tailored AI that tailors first-stage on `priormed` and
second-stage on response status and `adherence`:

![The more deeply-tailored adaptive intervention learned using
Q-learning](assets/more_deeply_tailored_AI.png){fig-align="center"
width="800"}

To estimate the mean outcome under the proposed decision rules we use
what we learned in the Primary Aims module and create an indicator for
those individuals observed to be consistent with the more deeply
tailored AI.

The optimal decision rules at each stage:

$$
A_1^{opt} = \begin{cases} 
1  \text{ BMOD} & \text{ if } \text{ priormed} = 0 \\
-1 \text{ MED} & \text{ if } \text{ priormed} = 1 
\end{cases}
$$

$$
A_2^{opt} = \begin{cases} 
1  \text{ INT} & \text{ if } \text{ adherence} = 1 \\
-1 \text{ AUG} & \text{ if } \text{ adherence} = 0 
\end{cases}
$$

We can write a simple function to that returns TRUE if an individual is
consistent with the more deeply tailored AI and FALSE if otherwise

```{r}
# Functions that returns TRUE if individual is consistent with QL adaptive intervention decision rule
QL_rule <- function(priormed, A1, R, adherence, A2) {
  # First-stage rule
  if ((priormed == 1 & A1 == -1) | (priormed==0 & A1 == 1)) {
    if (R == 1) {
      return(TRUE)
    } 
    # Second-stage rule, among non-responders
    else if ((adherence == 1 & A2 == 1) | (adherence == 0 & A2 == -1)) {
      return(TRUE)
    } 
    else {
      return(FALSE)
    }
    
  } 
  else {
    return(FALSE)
  }
}
```

```{r}
dat_adhd_QL <- dat_adhd %>% rowwise %>%
  mutate(QL = QL_rule(priormed, A1, R, adherence, A2))

dat_adhd_QL %>% kable() %>%
  kable_styling() %>%
  scroll_box(height = "200px")
```

### Estimate mean of more deeply tailored AI

Finally, we fit a simple regression model to the `dat_adhd_QL`
data.frame which contains an indicator for those consistent with the
learned decision rules

```{r}
# remember to add weights! Non-Responders are underrepresented
dat_adhd_QL <- dat_adhd_QL %>% mutate(weights = if_else(R==1, 2, 4))

mod_QL_rule <- lm(Y2 ~ QL, data = dat_adhd_QL, weights = weights)

C = rbind("Proposed QL AI" = c(1,1))

QL_estimate <- estimate(mod_QL_rule, C)
QL_estimate
```

### Comparing QL adaptive intervention to the four embedded AIs

![](assets/QL_tailoring.png)\

### Knowledge check #3

::: callout-note
#### Question

1.  Why do we need to use Q-learning to estimate a more deeply-tailored
    AI that uses intermediate variables? Could we use a single
    regression model?
:::

------------------------------------------------------------------------

The steps we just covered illustrate the basics of Q-learning using
moderated regression models. However, if we want to do inference on the
first-stage decision rule we need some extra software... enter
`qlaci()`!

# The `qlaci` package

The `qlaci` package performs Q-learning on data arising from a two-stage
SMART. It is useful when we need standard errors for the estimates of
our more deeply-tailored adaptive intervention.

::: callout-tip
The qlaci package can be downloaded from the d3c github using `remotes`
or `devtools`:
[d3center-isr/qlaci](https://github.com/d3center-isr/qlaci)
:::

Start by grand mean center the baseline covariates. This does not change
the point estimates, but is useful when interpreting model coefficients
or for hand coding contrasts.

```{r}
# Grand mean center all baseline covariates, append '_c' for centered
dat_adhd_c <- dat_adhd %>% mutate(across(c(odd, severity, priormed, race),
                                         ~ .x - mean(.x), 
                                         .names = "{.col}_c"))
```

Next, we specify the contrast matrix that will be used for the stage 1
regression (step 3 of Q-learning). `qlaci()` uses this matrix to
estimate the mean outcomes under each of the first-stage treatments
(accounting for the future optimal decision) at both levels of
`priormed`. We also specify a contrast that estimates the mean outcome
if everyone in the study had received the optimal more deeply-tailored
AI.

```{r}

## contrast matrix - we must transpose this for qlaci
c1 <-
  rbind(
    "Mean Y under bmod, prior med"          = c(1, rep(0, 3), 1,  1,  1),
    "Mean Y under med, prior med"           = c(1, rep(0, 3), 1, -1, -1),
    "Mean diff (bmod-med) for prior med"    = c(0, rep(0, 3), 0,  2,  2),
    "Mean Y under bmod, no prior med"       = c(1, rep(0, 3), 0,  1,  0),
    "Mean Y under med, no prior med"        = c(1, rep(0, 3), 0,  -1, 0),
    "Mean diff (bmod-med) for no prior med" = c(0, rep(0, 3), 0,  2,  0)
    )
```

::: {.callout-tip collapse="true" appearance="simple" icon="false"}
## qlaci() parameters

The following are the arguments we need to provide to `qlaci()`:

-   `H10`: Baseline covariates we want to adjust for in the first-stage
    regression.
-   `H11`: Variables that interact with first-stage treatment in the
    first-stage regression (candidate variables for deeper tailoring).
-   `A1`: Indicator for first-stage treatment
-   `Y1`: A continuous intermediate outcome. Here, we don't have an
    intermediate outcome, so we set this to zero for everyone.
-   `H20`: A matrix, with each column containing data for a main-effects
    term in the second-stage regression (analogous to `H10`).
-   `H21`: Variables that interact with second-stage treatment `A2` in
    the second-stage regression (candidate variables for deeper
    tailoring).
-   `A2`: Indicator for second-stage treatment
-   `Y2`: End-of-study outcome
-   `S`: Indicator for whether an individual was re-randomized (1 =
    re-randomized; 0 = otherwise)
-   `c1`: Contrast matrix for first-stage regression (see above)
:::

The function `qlaci()` maximizes the expected outcome for each stage of
treatment given a set of moderators.

```{r}
#| cache: true
attach(dat_adhd_c) # with attach we can be lazy and refer to variables in the data.frame by name directly

q1 <-  qlaci::qlaci(H10 = cbind(1, odd_c, severity_c, race_c, priormed),
                   H11 = cbind(A1 = 1, "A1:priormed" = priormed),
                   A1 = A1,
                   Y1 = rep(0, nrow(dat_adhd_c)), # set to zero for everyone; we care only about EOS outcome
                   H20 = cbind(1, odd_c, severity_c, race_c, priormed_c, A1, adherence),
                   H21 = cbind(A2 = 1, "A2:A1" = A1, "A2:adherence" = adherence, "A2:A1:adeherence" = A1*adherence),
                   A2 = A2,
                   Y2 = Y2,
                   S = 1 - R,
                   c1 = t(c1))

detach(dat_adhd_c)
```

## qlaci results

The the coefficients estimated by `qlaci()` combined with the user
specified contrast matrix give us the estimated means for first-stage
treatment options by levels of `priormed,` accounting for the optimal
second-stage tactic for non-responders. With valid confidence intervals
we can test contrasts and even compare to the 4 embedded adaptive
interventions found in Virtual Module 2!

```{r}
#| tbl-cap: "First-stage decision rule tailoring on priormed given optimal second-stage tailoring on response status and adherence"
q1$ci1
```

### Knowledge check #4

::: callout-note
#### Question

1.  Looking at the above table, what do the two contrasts (bmod - med)
    for levels of prior med tell us about tailoring?
:::
