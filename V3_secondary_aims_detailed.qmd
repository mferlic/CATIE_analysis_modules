---
title: "V3: Secondary Aims Analysis"
subtitle: "Using moderators and Q-learning to construct more deeply-tailored Adaptive Interventions"
author:   
  - name: Mason Ferlic
    orcid: 0000-0003-4170-2722
  - name: Jamie Yap
    orcid: 0000-0002-0899-7146
  - name: John J. Dziak
    orcid: 0000-0003-0762-5495
  - name: Daniel Almirall
    orcid: 0000-0002-9697-6600
format: 
  html:
    page-layout: full
    df-print: kable
    code-overflow: scroll
    code-line-numbers: true
    code-block-bg: true
    toc: true
    toc-location: left
    toc-depth: 3
    number-sections: true
    number-depth: 2
    embed-resources: true
editor: visual
editor_options: 
  chunk_output_type: inline
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(tidy = TRUE, fig.pos = 'H', warning = FALSE, message = FALSE, digits = 2)

options(digits = 3)
```

# Learning Goals

Learn how moderators of first and second-stage treatment effects can be used to construct optimal adaptive interventions

-   Fit moderated regression models

-   Test contrasts and generate interaction plots

Learn how Q-learning estimates the effect of a more-deeply tailored AI

-   Implement using the R Package `qlaci`

# Setup

Load required packages

```{r}
#| results: hide
#| warning: false

library(geepack)
library(ggplot2)
library(dplyr)
library(emmeans)
library(qlaci)
```

# Load data

This is data that was *simulated* to mimic data arising from the ADHD SMART study (PI: William Pelham). An accompanying handout ("ADHD Handout.pdf") describes the variables in the data set.

```{r}
# Load data
dat_adhd <- read.csv("data/adhd-simulated-2023.csv")
```

![ADHD study prototypical SMART](assets/adhd_smart.png){alt="ADHD study prototypical SMART" fig-align="center"}

## Examine data

::: {.callout-note collapse="true" appearance="simple" icon="false"}
## ADHD dataset variable descriptions

**Baseline covariates:**

-   `ID` subject identifier

-   `odd` Oppositional Defiant Disorder diagnosis, reflecting whether the child was (coded as 1) or was not (coded as 0) diagnosed with ODD before the first-stage intervention.

-   `severity` ADHD score, reflecting ADHD symptoms at the end of the previous school year (larger values reflect greater symptoms). Range 0-10.

-   `priormed` medication prior to first-stage intervention, reflecting whether the child did (coded as 1) or did not (coded as 0) receive medication during the previous school year.

-   `race` white (coded 1) versus non-white (coded 0).

**Intermediate covariates:**

-   `R` response status. R = 0 if child was classified as non-responder to first stage intervention, R= 1 if they were classified as a responder.

-   `NRtime` months at which child was classified as non-responder. Range 2-8. Undefined for responders.

-   `adherence` adherence to the stage 1 intervention. Reflecting whether the child did (coded as 1) or did not (coded as 0) show high adherence to initial treatment.

**Treatments:**

We use effect coding (sum to zero) to denote the two levels of treatment assignment. The primary benefit of effect coding is that we get interpretable estimates of both the main effects and interactions. WHY DO WE EFFECT CODE?

-   `A1` stage 1 treatment assignment. Randomized with probability $0.5$ to Medication (MED, $A1=-1$) or Behavioral Intervention (BMOD, $A1=1$).

-   `A2` stage 2 treatment assignment for non-responders. Non-responders we randomized with probability $0.5$ to receive Augmented (AUG, $A2=-1$) or Intensified (INT, $A2=1$) care. Undefined for responders.

**Outcomes**

-   `Y0` baseline school performance (higher values reflect better performance).

-   `Y1` mid-year school performance.

-   `Y2` end-of-year school performance (primary outcome for analysis)
:::

```{r}
#| tbl-cap: "ADHD SMART data"
head(dat_adhd, n = 10)
```

## Clean/transform data

Here we grand mean center the baseline covariates. This does not change the point estimates, but is useful when interpreting model coefficients or when hand coding contrasts.

```{r}
# Grand mean center all baseline covariates, append '_c' for centered
dat_adhd_c <- dat_adhd %>% mutate(odd_c = odd - mean(odd),
                          severity_c = severity - mean(severity),
                          priormed_c = priormed - mean(priormed),
                          race_c = race - mean(race))
```

------------------------------------------------------------------------

# Moderators of stage 2 treatment

A common secondary aim is to learn whether we can use baseline or intermediate covariates to select an optimal second-stage tactic for **non-responders.** For example, whether covariates such as the initial treatment $A_1$ and adherence to initial treatment `adherence` moderate the effect of $A2$.

> We hypothesize that for children who are non-adherent to first-stage treatment it will be better to AUGment ($A2=-1$) with the alternative treatment as opposed to INTensifying ($A2=1$) the current treatment.

## Regression model

We test this secondary aim by fitting a **moderated regression model** using data from non-responders. This model examines whether binary intermediate outcome variable `adherence`, and first-stage treatment $A_1$, moderate the effect of second-stage treatment $A_2$ on end-of-year outcome $Y_2$, controlling for other baseline covariates $\mathbf{X}$. The model is as follows:

$$
\begin{gather*} 
E[Y \mid \mathbf{X}, A_1, \text{adherence}, A_2, R = 0] = \eta_0 + \eta^T\mathbf{X} + \eta_1 A_{1} + \eta_2\text{adherence} + \beta_1 A_2 + \\ 
\beta_2 (A_2 \times A_1) + \beta_{3} (A_2 \times \text{adherence})
\end{gather*}
$$ {#eq-mod2}

::: callout-note
We interact $A_2$ with the uncentered variable `adherence` since we are interested in the effect of $A2$ at the each of the two levels: adherent (0) and non-adherent (1).
:::

First, subset data.frame to non-responders $(R=0)$

```{r}
dat_adhd_nr <- subset(dat_adhd, R == 0) # subset data.frame to non-responders

head(dat_adhd_nr) # view top 6 rows
```

Next, fit a moderated regression to the subset of non-responders. Interact $A_2$ with $A_1$ and `adherence`

```{r}
# geeglm fits a Generalize Estimating Equation. Similar to lm(), but gives us robust standard errors.
mod2 <- geepack::geeglm(Y2 ~ odd + severity + priormed + race + adherence + A1 + A2 + A1:A2 + adherence:A2, 
                        id = ID, # a subject identifier is required for geeglm()
                        data = dat_adhd_nr)

summary(mod2)
```

::: callout-warning
Only the second-stage coefficients $\beta$ from the moderated regression in @eq-mod2 are causal. The first-stage coefficients $\eta$ are biased as a result of sub-setting to non-responders.
:::

\
The regression model from @eq-mod2 gives us the effect of $A2$ among non-responders. Looking at the output we find that `adherence` is a significant moderator of stage 2 treatment, but $A_1$ is not.

## Knowledge check #1

::: callout-note
### Questions

1.  Why do we subset to non-responders when fitting a second-stage moderated regression?

2.  What does this regression tell us about the use of $A1$ as a tailoring variable?
:::

## Marginal means of stage 2

We will use a very powerful package called `emmeans` to estimate the marginal mean of end-of-year school performance under different treatment/covariate options. We could do this by writing custom contrasts of the model coefficients, but `emmeans` does this for us.

::: callout-note
Marginal means refers to estimating the expected value while holding some covariates constant and averaging over the rest.
:::

We use the fitted moderated regression model given in @eq-mod2 to estimate the average effect of second-stage treatments conditional on levels of adherence.

```{r}
# The formula notation denotes the mean outcome under all combination of the factors A1, A2, given levels of adherence.
# We specify weights=proportional since we want to average over the observed distribution of the other baseline covariates.
# df of Inf indicates CIs are computed using the standard normal distribution

em2 <- emmeans::emmeans(mod2, ~ A1 + A2 | adherence, weights = "proportional")
print(em2)
```

The results from the moderated regression and the estimate marginal means suggest that for those children who are non-adherent (`adherence` = 0) it is better to Augment ($A2 = -1$) rather than intensify. Likewise, for those children that are adherent (`adherence` = 1) it is better to Intensify ($A2=1$). Notice, our optimal tactic does not depend on first-stage treatment $A1$.

## Interaction plot of stage 2

We can also use the `emmeans` package to visualize the estimated mean outcome for non-responders under each tactic.

```{r}
ep2 <- emmeans::emmip(em2,  A1*A2 ~ adherence, style = "factor") # Interaction plot for trace.factors ~ x.factors
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Prettify the plot
ep2$data %>% mutate(across(1:3, as.factor)) %>%
  ggplot(aes(xvar, yvar, color = A2, linetype = A1, group = tvar)) +
  geom_line() +
  geom_point() +
  scale_color_manual("A2", values = c("-1" = "darkgreen", "1" = "purple"), 
                     labels = c("-1" = "-1 AUG", "1" = "1 INT")) +
  scale_linetype_manual("A1", values = c("-1" = 1,"1" = 6), 
                        labels = c("-1" = "-1 MED", "1" = "1 BMOD")) +
  labs(title = "Moderator analysis of stage 2 intervention options",
       x = "Adherence to stage 1",
       y = "EOS School Performance \n (higher is better)") +
  scale_x_discrete(labels = c("Non-adherent", "Adherent")) +
  theme_classic()
```

## Knowledge check #2

::: callout-note
### Questions

1.  What is the optimal tactic for non-adhering, non-responders to BMOD(1)? To MED(-1)?

2.  $A1$ was found to be not useful for tailoring, should we still include it in the regression model?
:::

------------------------------------------------------------------------

# Q-learning

We just found that `adherence` is useful for tailoring the second-stage tactic. We would like to do something similar and learn first-stage tailoring variables. Can't we just fit a moderated regression for first-stage, and taken together, we have a proposal for a more deeply-tailored AI? The answer is no! These separate regressions don't "talk" to each other. That is, we want to make the optimal first-stage decision accounting for the fact that in the future we will be making an optimal second-stage decision.

To estimate the effect of a more deeply-tailored adaptive intervention combining the optimal tactics at each stage we use Q-learning.

Q-learning has three steps:

1.  Fit stage 2 moderator regression (`mod2`!) âœ…
2.  Predict the stage 2 outcome under the optimal decision rule: $\hat{Y}^{opt}_i$
3.  Fit a stage 1 moderated regression on $\hat{Y}^{opt}_i$

## Predict optimal outcome

The optimal second-stage tactic learned from the moderated regression:

$$
A2 = \begin{cases} 
1  \text{ INT} & \text{ if } \text{ adherence} = 1 \\
-1 \text{ AUG} & \text{ if } \text{ adherence} = 0 
\end{cases}
$$

Create new data.frame with optimal $A2_i$ for every non-responding child

```{r}
# Assign optimal second-stage tactic
dat_adhd_nr_opt2 <- dat_adhd_nr %>% 
  mutate(A2 = if_else(adherence == 1, 1, -1)) # learned decision rule
```

Predicted outcome under optimal treatment assignment

```{r}
dat_adhd_nr_opt2$Y2_opt <- predict(mod2, newdata = dat_adhd_nr_opt2) # using the stage 2 moderated regression mode
```

Merge non-responders with the observed outcome from responders

```{r}
# Responders get assigned their observed outcome (no stage 2 tactic)
dat_adhd_r <- dat_adhd %>% filter(R == 1) %>%
  mutate(Y2_opt = Y2)

# combine non-responders w/ responders
dat_adhd_opt2 <- bind_rows(dat_adhd_nr_opt2, dat_adhd_r)
```

We now have a data frame with the estimated optimal outcome for non-responders tailored by `adherence.`

## First-stage tailoring controlling for optimal second-stage

In Virtual Module 2, we showed that starting an adaptive intervention with BMOD ($A1 = -1$) is better, on average, than MED ($A1 = -1$) on end-of-year school performance. A common secondary aim is whether we can use baseline information to learn an optimal first-stage tactic to build a more deeply-tailored AI.

> We hypothesize that children already on medication (`priormed` = 1) will be better-off, on average, starting with MED ($A1 = -1$) instead of BMOD ($A1 = 1$) due to parent/child habituation with taking medication.

## Regression model

We fit a moderated regression model for first-stage treatment using the `dat_adhd_opt2` data frame, which accounts for the optimal future second-stage tactic. The tailoring variable of interest is `priormed`.

$$
\begin{gather}
E[\hat{Y}^{opt} \mid \mathbf{X}, \text{priormed}, A_1] = \eta_0 + 
\eta^TX + \beta_1\text{priormed} + 
\beta_2A_1 + \beta_3(A_1 \times \text{priormed})
\end{gather}
$$ {#eq-Qmod1}

```{r}
# Moderator regression for first stage tailoring on priormed, controlling for optimal future tactic
Qmod1 <- geepack::geeglm(Y2_opt ~ odd + severity + race + A1*priormed,
                         id = ID,
                         data = dat_adhd_opt2)

summary(Qmod1)
```

::: callout-warning
The standard errors here are incorrect due to estimating $\hat{Y}^{opt}$. We need special software (see `qlaci`) to do proper inference.
:::

We use `emmeans` pacakge to estimate the expected end-of-year school performance for an adaptive intervention that offers BMOD(1) or MED(-1) at first-stage for levels of `priormed`, adjusting for the fact we are optimally tailoring second-stage treatment for non-responders on `adherence`.

```{r}
qem1 <- emmeans::emmeans(Qmod1, ~ A1 | priormed, weights = "proportional")
summary(qem1, infer = FALSE)
```

::: callout-warning
The standard errors here are incorrect due to estimating $\hat{Y}^{opt}$. We need special software (see `qlaci`) to do proper inference.
:::

## Interaction plot of optimal tactic

```{r}
# Interaction plot of A1 with priormed
qep1 <- emmeans::emmip(Qmod1, A1 ~ priormed, style = "factor", weights = "proportional")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Prettify plot  
qep1$data %>% mutate(across(1:2, as.factor)) %>%
  ggplot(aes(xvar, yvar, color = A1, group = tvar)) +
  geom_line(linewidth = 1) +
  geom_point() +
  scale_color_manual("A1", values = c("-1" = "red", "1" = "blue"), 
                     labels = c("-1" = "-1 MED", "1" = "1 BMOD")) +
  theme_classic() +
  labs(title = "Moderator of stage 1 controlling for optimal stage 2",
       x = "Medication use in Prior year",
       y = "EOS School Performance \n (higher is better)") +
  scale_x_discrete(labels = c("No prior med", "Prior med")) +
  scale_y_continuous(n.breaks = 8)
```

## Estimated mean under the more deeply-tailored AI

![The more deeply-tailored adaptive intervention estimated using Q-learning](assets/more_deeply_tailored_AI.png){fig-align="center" width="800"}

Here we create a new data frame with the optimal first-stage tactic by levels of `priormed`. We use the parametric g-formula and the fitted model from @eq-Qmod1 to compute the mean outcome of the more deeply-tailored adaptive intervention.

$$
A1 = \begin{cases} 
1  \text{ BMOD} & \text{ if } \text{ priormed} = 0 \\
-1 \text{ MED} & \text{ if } \text{ priormed} = 1 
\end{cases}
$$

```{r}
# Assign optimal second-stage tactic
dat_adhd_opt1 <- dat_adhd_opt2 %>% 
  mutate(A1 = if_else(priormed == 1, -1, 1)) # learned decision rule

# Predict outcome under optimal treatment a2
dat_adhd_opt1$Y2_opt <- predict(Qmod1, newdata = dat_adhd_opt1)

cat("Estimated school performance for optimal AI:", mean(dat_adhd_opt1$Y2_opt))
```

## Knowledge check #3

::: callout-note
### Questions

1.  Why do we need to use Q-learning to estimate a more deeply-tailored AI? What is wrong with simply running two moderator regressions?

2.  In the regression model `Qmod1` what does the main effect of $A1$ represent?

3.  If `priormed` did not moderate the effect of $A1$ would this still be a valid more deeply-tailored AI?
:::

------------------------------------------------------------------------

The steps we just covered illustrate the basics of Q-learning, but we only get point estimates, not standard errors. For that we need some advanced software.

# The `qlaci` package

The `qlaci` package performs Q-learning on data arising from a two-stage SMART. It is useful for when we want standard errors for the estimates of our more deeply-tailored adaptive intervention.

::: callout-note
The qlaci package can be downloaded from the d3c github: [d3center-isr/qlaci](https://github.com/d3center-isr/qlaci)
:::

First, we specify the contrast matrix that will be used for the stage-1 regression (step 3 of Q-learning). `qlaci()` uses this matrix to estimate the mean outcomes under each of the first-stage treatments (averaging over the future optimal response) at both levels of `priormed`. We also specify a contrast that estimates the mean outcome if everyone in the study had received the optimal more deeply-tailored AI.

```{r}
pPM <- mean(dat_adhd_c$priormed) # probability of priormed

## contrast matrix - we must transpose this for qlaci
c1 <-
  rbind(
    "Mean Y under bmod, prior med"          = c(1, rep(0, 3), 1,  1,  1),
    "Mean Y under med, prior med"           = c(1, rep(0, 3), 1, -1, -1),
    "Mean diff (bmod-med) for prior med"    = c(0, rep(0, 3), 0,  2,  2),
    "Mean Y under bmod, no prior med"       = c(1, rep(0, 3), 0,  1,  0),
    "Mean Y under med, no prior med"        = c(1, rep(0, 3), 0,  -1, 0),
    "Mean diff (bmod-med) for no prior med" = c(0, rep(0, 3), 0,  2,  0),
    "Mean Y Optimal AI"                    = c(1, rep(0, 3), pPM, 1 - 2 * pPM, -pPM)
    )
```

NOTE: CAN WE ESTIMATE THE MORE DEEPLY TAILORED AI THIS WAY? are the CI valid or do we need to account for the uncertainty in pPM?? Bootstrap? Delta-method?

::: {.callout-note collapse="true" appearance="simple" icon="false"}
## qlaci() parameters

The following are the arguments we need to provide to `qlaci()`:

-   `H10`: Baseline covariates we want to adjust for in the first-stage regression.
-   `H11`: Variables that interact with first-stage treatment in the first-stage regression (candidate variables for deeper tailoring).
-   `A1`: Indicator for first-stage treatment
-   `Y1`: A continuous intermediate outcome. Here, we don't have an intermediate outcome, so we set this to zero for everyone.
-   `H20`: A matrix, with each column containing data for a main-effects term in the second-stage regression (analogous to `H10`).
-   `H21`: Variables that interact with second-stage treatment `A2` in the second-stage regression (candidate variables for deeper tailoring).
-   `A2`: Indicator for second-stage treatment
-   `Y2`: End-of-study outcome
-   `S`: Indicator for whether an individual was re-randomized (1 = re-randomized; 0 = otherwise)
-   `c1`: Contrast matrix for first-stage regression (see above)
:::

```{r}
attach(dat_adhd_c) # with attach we can be lazy and refer to variables in the data.frame by name directly

q1 <-  qlaci::qlaci(H10 = cbind(1, odd_c, severity_c, race_c, priormed),
                   H11 = cbind(A1 = 1, "A1:priormed" = priormed),
                   A1 = A1,
                   Y1 = rep(0, nrow(dat_adhd_c)), # set to zero for everyone; we care only about EOS outcome
                   H20 = cbind(1, odd_c, severity_c, race_c, priormed, A1, adherence),
                   H21 = cbind(A2 = 1, "A2:A1" = A1, "A2:adherence" = adherence),
                   A2 = A2,
                   Y2 = Y2,
                   S = 1 - R,
                   c1 = t(c1))

detach(dat_adhd_c)
```

## qlaci results

The the coefficients estimated by `qlaci()` combined with the user specified contrast matrix give us the estimated means for first-stage treatment options by levels of `priormed,` accounting for the optimal second-stage tactic for non-responders. With valid confidence intervals we can test contrasts and even compare the the 4 embedded adaptive interventions.

```{r}
#| tbl-cap: "Estimated optimal AI tailoring first-stage on priormed and second-stage on response status and adherence"
data.frame(q1$ci1)
```

## Knowledge check #4

::: callout-note
### Questions

1.  Looking at the above table, what do the two contrasts (bmod - med) for levels of prior med tell us about tailoring?
2.  
:::
